<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Nitin Kamra</title>

  <meta name="description" content="Home Page for Nitin Kamra">
  <meta name="author" content="Nitin Kamra">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Nitin Kamra
                  </p>
                  <p>
                    I am a Research Scientist at <a href="https://tech.facebook.com/reality-labs/">Reality Labs Research, Meta</a>. I work on policy learning for dexterous manipulation with humanoid robots. Before this, I was working on developing agentic AI and reinforcement learning algorithms for assistive agents to provide guidance to users in performing day-to-day tasks.
                  </p>
                  <p>
                    I graduated with a Ph.D. in Computer Science and an MS in Intelligent Robotics from the University of Southern California (USC) in May 2021, advised by <a href="http://www-bcf.usc.edu/~liu32/index.html"> Yan Liu</a>. My research focused on prediction and learning in multi-agent settings. I also hold an undergraduate degree in Electrical Engineering from IIT Delhi.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:nitinkamra1992@gmail.com"><img src="ico/email.png" style="height:35px"></a> &nbsp;&nbsp;
                    <a href="https://scholar.google.com/citations?user=Qn_rbIgAAAAJ&hl=en"><img src="ico/ralohcs.png" style="height:35px"></a> &nbsp;&nbsp;
                    <a href="https://www.linkedin.com/in/nitin-kamra-40abb048"><img src="ico/nideknil.png" style="height:35px"></a> &nbsp;&nbsp;
                    <a href="https://github.com/nitinkamra1992"><img src="ico/buhtig.png" style="height:35px"></a> &nbsp;&nbsp;
                    <a href="https://x.com/nitinkamra1992"><img src="ico/x.png" style="height:35px"></a>
                  </p>
                </td>
                <td style="padding:2.5%;width:50%;max-width:50%">
                  <a href="images/nkamra.png"><img style="width:80%;max-width:80%;object-fit: cover; border-radius: 10%;" alt="profile photo" src="images/nkamra.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in understanding "understanding" itself, aiming to develop architectures for artificial agents to achieve human-level understanding. My research spans deep reinforcement learning, continual learning, robotics, reasoning, and planning.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Publications</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h3>Learning and Planning for Embodied Agents</h3>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- digidata -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/digidata.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://facebookresearch.github.io/DigiData/">
                    <span class="papertitle">DigiData: Training and Evaluating General-Purpose Mobile Control Agents</span>
                  </a>
                  <br>
                  Yuxuan Sun, Manchen Wang, Shengyi Qian, William R. Wong, Eric Gan, Pierluca D'Oro, Alejandro Castillejo Munoz, Sneha Silwal, Pedro Matias, <strong>Nitin Kamra</strong>, Satwik Kottur, Nick Raines, Xuanyi Zhao, Joy Chen, Joseph Greer, Andrea Madotto, Allen Bolourchi, James Valori, Kevin Carlberg, Karl Ridgeway and Joseph Tighe
                  <br>
                  <em>ArXiv</em>, 2025
                  <p>
                    We introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks.
                  </p>
                  <p>
                    <a href="https://facebookresearch.github.io/DigiData/">Webpage</a> |
                    <a href="https://arxiv.org/abs/2511.07413">ArXiv</a> |
                    <a href="https://github.com/facebookresearch/DigiData">Code</a> |
                    <a href="">Dataset</a> |
                    <a href="bib/sun2025digidata.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- wagibench -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/wagibench.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://facebookresearch.github.io/WAGIBench/">
                    <span class="papertitle">Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents</span>
                  </a>
                  <br>
                  Vijay Veerabadran, Fanyi Xiao, <strong>Nitin Kamra</strong>, Pedro Matias, Joy Chen, Caley Drooff, Brett D Roads, Riley Williams, Ethan Henderson, Xuanyi Zhao, Kevin Carlberg, Joseph Tighe and Karl Ridgeway
                  <br>
                  <font color="#1772d0"><strong>(Spotlight)</strong></font> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2025
                  <p>
                    This work focuses on creating a strong benchmark to measure progress in solving the egocentric multimodal goal inference problem for assistive wearable agents using vision-language models (VLMs).
                  </p>
                  <p>
                    <a href="https://facebookresearch.github.io/WAGIBench/">Webpage</a> |
                    <a href="https://arxiv.org/abs/2510.22443">ArXiv</a> |
                    <a href="https://openreview.net/pdf?id=REG4cJItSZ">Paper</a> |
                    <a href="https://github.com/facebookresearch/WAGIBench">Code</a> |
                    <a href="https://dl.fbaipublicfiles.com/wagibench/ob2.tar.gz">Dataset</a> |
                    <a href="pdf/wagibench_poster.png">Poster</a> |
                    <a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/121655">NeurIPS talk</a> |
                    <a href="bib/veerabadran2025wagibench.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- genie -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <div class="two" style="opacity:0; width:100%; height:100%; background: #eee;">
                    </div>
                    <img src='images/genie.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <span class="papertitle">Language-based Hierarchical Goal Decomposer and API Executor</span>
                  <br>
                  <strong>Nitin Kamra</strong>
                  <br>
                  <em>Reality Labs Research, Meta</em>, 2024
                  <p>
                    Language-based Hierarchical Goal Decomposer and API Executor.
                  </p>
                </td>
              </tr>

              <!-- lifeplanner -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/lifeplanner.png' onerror="this.style.display='none'" width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2311.04403">
                    <span class="papertitle">Human-Centered Planning</span>
                  </a>
                  <br>
                  Yuliang Li, <strong>Nitin Kamra</strong>, Ruta Desai and Alon Halevy
                  <br>
                  <em>ArXiv</em>, Nov 2023
                  <p>
                    We develop an LLM-based planner (LLMPlan) extended with the ability to self-reflect on its output.
                  </p>
                  <p>
                    <a href="https://arxiv.org/abs/2311.04403">ArXiv</a> |
                    <a href="bib/li2023lifeplanner.bib">Bibtex</a>
                  </p>
                </td>
              </tr>


              <!-- ctg -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/ctg.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <span class="papertitle">Zero-shot Compositional Generalization with Conjugate Task Graphs</span>
                  <br>
                  <strong>Nitin Kamra</strong> and Rohan Chitnis
                  <br>
                  <em>Reality Labs Research, Meta</em>, 2023
                  <br>
                  <p>
                    Zero-shot Compositional Generalization with Conjugate Task Graphs.
                  </p>
                </td>
              </tr>

              <!-- llmvizplan -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/llmvizplan.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/ICCV2023/html/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.html"><span class="papertitle">Pretrained Language Models as Visual Planners for Human Assistance</span>
                  </a>
                  <br>
                  Dhruvesh Patel, Hamid Eghbalzadeh, <strong>Nitin Kamra</strong>, Michael Louis Iuzzolino, Unnat Jain and Ruta Desai
                  <br>
                  <em>International Conference on Computer Vision (ICCV)</em>, Oct 2023
                  <br>
                  <small>A short version appears in <em>ICCV Workshop on Assistive Computer Vision and Robotics (ACVR)</em>, Oct 2023</small>
                  <p>
                    We show that pretrained Vision Language Models can act as visual planners for human assistance.
                  </p>
                  <p>
                    <a href="https://arxiv.org/abs/2304.09179">ArXiv</a> |
                    <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.html">Paper</a> |
                    <a href="https://github.com/facebookresearch/VLaMP">Code</a> |
                    <a href="bib/patel2023llmvizplan.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- egotv -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/egotv.png' onerror="this.style.display='none'" width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/ICCV2023/html/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.html"><span class="papertitle">EgoTV: Egocentric Task Verification from Natural Language Task Descriptions</span>
                  </a>
                  <br>
                  Rishi Hazra, Brian Chen, Akshara Rai, <strong>Nitin Kamra</strong> and Ruta Desai
                  <br>
                  <em>International Conference on Computer Vision (ICCV)</em>, Oct 2023
                  <p>
                    We propose a benchmark and a synthetic dataset called Egocentric Task Verification (EgoTV) to enable egocentric agents to understand everyday tasks. The goal in EgoTV is to verify the execution of tasks from egocentric videos based on the natural language description of these tasks.
                  </p>
                  <p>
                    <a href="https://arxiv.org/abs/2303.16975">ArXiv</a> |
                    <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.html">Paper</a> |
                    <a href="https://github.com/facebookresearch/EgoTV">Code</a> |
                    <a href="https://ai.meta.com/datasets/egotv-egocentric-task-verification-dataset/">Dataset</a> |
                    <a href="bib/hazra2023egotv.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- adtg -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/adtg.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2302.05330"><span class="papertitle">Action Dynamics Task Graphs for Learning Plannable Representations of Procedural Tasks</span>
                  </a>
                  <br>
                  Weichao Mao, Ruta Desai, Michael Louis Iuzzolino and <strong>Nitin Kamra</strong>
                  <br>
                  <em>AAAI Workshop on User-Centric Artificial Intelligence for
                    Assistance in At-Home Tasks</em>, Feb 2023
                  <p>
                    Given video demonstrations and paired narrations of an at-home procedural task, we present an approach to extract the underlying task structure - relevant actions and their temporal dependencies - via action-centric task graphs.
                  </p>
                  <p>
                    <a href="https://arxiv.org/abs/2302.05330">ArXiv</a> |
                    <a href="https://ai4athome.github.io/res/papers/mao_action_dynamics_task.pdf">Paper</a> |
                    <a href="bib/mao2023adtg.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- morp -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/morp.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2301.09854">
                    <span class="papertitle">Effective Baselines for Multiple Object Rearrangement Planning in Partially Observable Mapped Environments</span>
                  </a>
                  <br>
                  Engin Tekin, Elaheh Barati, <strong>Nitin Kamra</strong> and Ruta Desai
                  <br>
                  <em>AAAI Workshop on User-Centric Artificial Intelligence for
                    Assistance in At-Home Tasks</em>, Feb 2023
                  <p>
                    Our goal is to enable home-assistive intelligent agents to efficiently plan for rearrangement under partially observed, but mapped environments. We investigate both monolithic and modular deep reinforcement learning methods for planning in this setting.
                  </p>
                  <p>
                    <a href="https://arxiv.org/abs/2301.09854">ArXiv</a> |
                    <a href="https://ai4athome.github.io/res/papers/tekin_effective_baselines.pdf">Paper</a> |
                    <a href="bib/tekin2023morp.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h3>Learning in Multiagent Systems</h3>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- phdthesis -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/phdthesis.jpg' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://digitallibrary.usc.edu/Share/5825p2w24dj21h8fpbhsllu03527567w"><span class="papertitle">Machine Learning in Interacting Multi-agent Systems</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>
                  <br>
                  <em>PhD Thesis (University of Southern California)</em>, Jul 2021
                  <p>
                    I propose methods to advance the state-of-the-art for several multi-agent prediction, control and learning problems.
                  </p>
                  <p>
                    <a href="pdf/phdthesis.pdf">Pdf</a> |
                    <a href="https://digitallibrary.usc.edu/Share/5825p2w24dj21h8fpbhsllu03527567w">Link</a> |
                    <a href="bib/kamra2021thesis.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- diffcvg2 -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/diffcvg.png' onerror="this.style.opacity=0" width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://proceedings.mlr.press/v161/kamra21a.html"><span class="papertitle">Gradient-based Optimization for Multi-resource Spatial Coverage Problems</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong> and Yan Liu
                  <br>
                  <em>Conference on Uncertainty in Artificial Intelligence (UAI)</em>, Jul 2021
                  <br>
                  <small>A short version appears in <em>NeurIPS workshop on Interpretable Inductive Biases and Physically Structured Learning</em>, 2020</small>
                  <p>
                    We propose the coverage gradient theorem, which provides a gradient estimator for a broad class of spatial coverage objectives using a combination of Newton-Leibniz theorem and implicit boundary differentiation. Our framework approximates the coverage objectives and their gradients using spatial discretization and solves several multi-resource spatial coverage problems efficiently via gradient-based optimization.
                  </p>
                  <p>
                    <a href="https://proceedings.mlr.press/v161/kamra21a.html">Paper</a> |
                    <a href="https://inductive-biases.github.io/papers/26.pdf">Workshop</a> |
                    <a href="https://slideslive.com/38941441/gradientbased-optimization-for-multiresource-coverage-problems">Video</a> |
                    <a href="bib/kamra2021diffcvg2.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- mapred2 -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/mapred2.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2010.15891"><span class="papertitle">Multi-agent Trajectory Prediction with Fuzzy Query Attention</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, Hao Zhu, Dweep Trivedi, Ming Zhang and Yan Liu
                  <br>
                  <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2020
                  <br>
                  <small>A short version appears in <em>Southern California Machine Learning Symposium (SCMLS)</em>, 2020</small>
                  <p>
                    We present an architecture to address the challenge of trajectory prediction for scenes with multiple agents and entities. We model crucial inductive biases of motion, namely, inertia, relative motion, intents and interactions via a relational model to flexibly capture interactions between agents in diverse environments. Specifically, we propose a novel attention mechanism which models interactions by making continuous-valued (fuzzy) decisions and learning the corresponding responses. Our architecture demonstrates significant gains over existing state-of-the-art models in diverse domains such as human crowds, freeway traffic, sports trajectories and physics.
                  </p>
                  <p>
                    <a href="https://proceedings.neurips.cc/paper/2020/hash/fe87435d12ef7642af67d9bc82a8b3cd-Abstract.html">Paper</a> |
                    <a href="https://cseweb.ucsd.edu/~jmcauley/workshops/scmls20/papers/scmls20_paper_4.pdf">Symposium</a> |
                    <a href="https://arxiv.org/abs/2010.15891">ArXiv</a> |
                    <a href="https://github.com/nitinkamra1992/FQA">Code</a> |
                    <a href="bib/kamra2020mapred2.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- deepfp -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/deepfp.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-030-32430-8_15"><span class="papertitle">DeepFP for Finding Nash Equilibrium in Continuous Action Spaces</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, Umang Gupta, Kai Wang, Fei Fang, Yan Liu and Milind Tambe
                  <br>
                  <em>Conference on Decision and Game Theory for Security (GameSec)</em>, 2019
                  <br>
                  <small>A short version appears in <em>International Conference on Autonomous Agents and Multiagent Systems (AAMAS)</em>, 2019</small>
                  <p>
                    We present DeepFP, an extension of fictitious play for finding nash equilibrium of two-player zero-sum games in continuous action spaces. DeepFP represents players’ best responses via generative neural networks which are highly expressive implicit density approximators and trains them end-to-end in an actor-critic style framework.
                  </p>
                  <p>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-32430-8_15">Paper</a> |
                    <a href="https://dl.acm.org/citation.cfm?id=3332004">AAMAS abstract</a> |
                    <a href="pdf/deepfp.pdf">Pdf</a> |
                    <a href="bib/kamra2019deepfp.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- optgradfp2 -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/optgradfp2.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16525"><span class="papertitle">Policy Learning for Continuous Space Security Games using Neural Networks</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, Umang Gupta, Fei Fang, Yan Liu and Milind Tambe
                  <br>
                  <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, Feb 2018
                  <br>
                  <small>A short version appears in <em>IJCAI International Workshop on A.I. in Security (IWAISe)</em>, Aug 2017</small>
                  <p>
                    We present OptGradFP, a novel deep learning based approach for continuous space security games, that searches for the optimal defender strategy in a parameterized continuous search space, and can be used to learn policies over multiple game states simultaneously.
                  </p>
                  <p>
                    <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16525">Paper</a> |
                    <a href="http://iwaise.it.nuigalway.ie/wp-content/uploads/2017/09/iwaise-proceedings.pdf#page=22">Workshop</a> |
                    <a href="pdf/optgradfp.pdf">Workshop pdf</a> |
                    <a href="pdf/optgradfp2_ppt.pdf">Slides</a> |
                    <a href="bib/kamra2018policy.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- combprobmrs -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/combprobmrs.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="http://ieeexplore.ieee.org/abstract/document/8125731/"><span class="papertitle">Combinatorial Problems in Multi-Robot Battery Exchange Systems</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, T. K. Satish Kumar and Nora Ayanian
                  <br>
                  <em>IEEE Transactions on Automation Science and Engineering (T-ASE)</em>, 2018
                  <p>
                    We present approximation algorithms with heuristics to address combinatorial problems that arise in multirobot delivery systems involving multiple aspects of resource scheduling and path planning that make them more complex than well-known combinatorial problems studied in operations research.
                  </p>
                  <p>
                    <a href="http://ieeexplore.ieee.org/abstract/document/8125731/">Paper</a> |
                    <a href="bib/kamra2018combprobmrs.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- dramas -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/dramas.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7294146"><span class="papertitle">A mixed integer programming model for timed deliveries in multirobot systems</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong> and Nora Ayanian
                  <br>
                  <em>IEEE International Conference on Automation Science and Engineering (CASE)</em>, Aug 2015
                  <p>
                    We present a solution to enable task robots to operate in long-duration autonmous missions by requesting resources (e.g. batteries) from a distribution center, which can deploy “delivery robots” to fulfill those requests. We address the scheduling problem with: (a) multiple incoming time-bound requests from the task robots, (b) priorities on task robots, (c) relaxed scheduling when available resources are scant, and (d) dynamic re-routing of delivery robots. The problem is posed as a variant of the Vehicle Routing Problem with Time Windows, and solved as a Mixed Integer Quadratic Program using a branch and bound based solver.
                  </p>
                  <p>
                    <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7294146">Paper</a> |
                    <a href="pdf/dramas_poster.pdf">Poster</a> |
                    <a href="pdf/dramas_ppt.pdf">Slides</a> |
                    <a href="bib/kamra2015mixed.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- locrobot -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/locrobot.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="pdf/locrobot.pdf"><span class="papertitle">RF-Based Relative Localization for Robot Swarms</span>
                  </a>
                  <br>
                  Wolfgang Hoenig and <strong>Nitin Kamra</strong>
                  <br>
                  <em>University of Southern California (USC)</em>, 2015
                  <p>
                    We present a simple gradient-descent based localization approach based on detection of RF signals from robots, which scales efficiently to large number of robots in a distributed swarm.
                  </p>
                  <p>
                    <a href="pdf/locrobot.pdf">Pdf</a>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h3>Machine Learning for Healthcare</h3>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- prl2 -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/prl2.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/document/9667722">
                    <span class="papertitle">Treatment Recommendation with Preference-based Reinforcement Learning</span>
                  </a>
                  <br>
                  Nan Xu, <strong>Nitin Kamra</strong> and Yan Liu
                  <br>
                  <em>IEEE International Conference on Big Knowledge (ICBK)</em>, 2021
                  <br>
                  <small>A short version also appears in <em>NeurIPS workshop on Deep Reinforcement Learning</em>, 2020
                  <p>
                    We present an open simulation platform to model the evolution of two diseases, namely Cancer and Sepsis, and individuals' reactions to the received treatment. We experimentally show that preference-based reinforcement learning, where the reward function is itself learned based on treatment goals without expert demonstrations, achieves high survival rate and low side effects, with inferred rewards being highly correlated to treatment goals.
                  </p>
                  <p>
                    <a href="https://sites.google.com/view/tr-with-prl/">Webpage</a> |
                    <a href="https://ieeexplore.ieee.org/document/9667722">Paper</a> |
                    <a href="pdf/prl2.pdf">Pdf</a> |
                    <a href="https://drive.google.com/file/d/1TzzR0sT_Au5IuW0_DgQomyHwwzF_0_RZ/view?usp=sharing">Workshop</a> |
                    <a href="https://slideslive.com/38941392/an-examination-of-preferencebased-reinforcement-learning-for-treatment-recommendation?ref=account-folder-62083-folders">Video</a> |
                    <a href="bib/xu2021prl2.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- polsird -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/polsird.png' onerror="this.style.opacity=0" width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://link.springer.com/article/10.1007%2Fs41666-021-00099-3"><span class="papertitle">PolSIRD: Modeling Epidemic Spread under Intervention Policies</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, Yizhou Zhang, Sirisha Rambhatla, Chuizheng Meng and Yan Liu
                  <br>
                  <em>Journal of Healthcare Informatics Research (J-HIR)</em>, Jun 2021
                  <p>
                    We present a mathematical model, namely PolSIRD, which represents evolution of epidemics without assuming full observability and while accounting for the effects of under-reporting and intervention policies. Our model applied to the spread of COVID-19 in the United States, outperforms the methods employed by the CDC in predicting the spread, and correctly predicts the second wave of the epidemic as a result of lifting the intervention policies prematurely.
                  </p>
                  <p>
                    <a href="https://link.springer.com/article/10.1007%2Fs41666-021-00099-3">Paper</a> |
                    <a href="https://arxiv.org/abs/2009.01894">ArXiv</a> |
                    <a href="bib/kamra2021polsird.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h3>General Machine Learning</h3>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- dgdmn -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/dgdmn.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/1710.10368"><span class="papertitle">Deep Generative Dual Memory Network for Continual Learning</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, Umang Gupta and Yan Liu
                  <br>
                  <em>ArXiv</em>, May 2018
                  <p>
                    We derive inspiration from human memory to develop an architecture capable of learning continuously from sequentially incoming tasks, while averting catastrophic forgetting. We present: (i) a dual memory architecture emulating the complementary learning systems (hippocampus and the neocortex) in the human brain, (ii) memory consolidation via generative replay of past experiences, and (iii) improved performance retention on challenging tasks even for low capacity models. Our architecture displays many characteristics of the mammalian memory and provides insights on the connection between sleep and learning.
                  </p>
                  <p>
                    <a href="posts/dgdmn/dgdmn.html">Webpage</a> |
                    <a href="https://arxiv.org/abs/1710.10368">ArXiv</a> |
                    <a href="bib/kamra2017dgdmn.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- dyngem -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/dyngem.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/1805.11273"><span class="papertitle">DynGEM: Deep Embedding Method for Dynamic Graphs</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>*, Palash Goyal*, Xinran He and Yan Liu
                  <br>
                  <em>IJCAI International Workshop on Representation Learning for Graphs (ReLiG)</em>, Aug 2017
                  <p>
                    DynGEM: Deep Embedding Method for Dynamic Graphs.
                  </p>
                  <p>
                    <a href="https://arxiv.org/abs/1805.11273">ArXiv</a> |
                    <a href="pdf/dyngem_ppt.pdf">Slides</a> |
                    <a href="code/dyngem_code.zip">Code</a> |
                    <a href="bib/kamra2017dyngem.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- zshotdact -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/zshotdact.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <span class="papertitle">Towards Zero-shot Dialog Act Classification</span>
                  <br>
                  <strong>Nitin Kamra</strong>, Daniel Elkind and Angeliki Metallinou
                  <br>
                  <em>Alexa Natural Understanding, Amazon</em>, 2020
                  <p>
                    We explore learning compact representations of task-oriented dialogs, called “dialog acts” (DAs), which comprise of a de-lexicalized grammar based on the general language patterns appearing in dialog interactions and compactly encode information about the intents and entities referenced in a conversation.
                    We train a recurrent deep learning module custom designed for mapping conversations to a sequence of dialog acts and achieve remarkable performance in the in-domain setup and reasonable success at generalizing in the zero-shot setup.
                  </p>
                </td>
              </tr>

              <!-- pgd -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/pgd.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="pdf/pgd.pdf">
                  <span class="papertitle">Parallel Gradient Descent for Multilayer Feedforward Neural Networks</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, Palash Goyal, Sungyong Seo and Vasilis Zois
                  <br>
                  <em>University of Southern California (USC)</em>, 2016
                  <p>
                    We implement parallelized gradient descent to train multilayer feedforward neural networks via various modes: (a) parallelly processing examples across threads, (b) parallelizing matrix operations for a single training example using threads, (c) a BLAS parallelized version, and (d) a CUDA implementation on a GPU. All implementations are compared for speedup obtained across network architectures and increasing problem sizes, along with a comparison with the deep learning library: Theano.
                  </p>
                  <p>
                    <a href="pdf/pgd.pdf">Pdf</a> |
                    <a href="pdf/pgd_ppt.pdf">Slides</a> |
                    <a href="https://github.com/nitinkamra1992/parallel-gradient-descent">Code</a>
                  </p>
                </td>
              </tr>

              <!-- rain -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/rain.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="pdf/rain.pdf">
                  <span class="papertitle">Predicting Rainfall with Polarimetric Radar Data</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong> and James Preiss
                  <br>
                  <em>Kaggle Competition</em>, 2015
                  <p>
                  </p>
                  <p>
                    <a href="pdf/rain.pdf">Pdf</a>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h3>Other Projects</h3>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- dtpa -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/dtpa.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="pdf/dtpa.pdf"><span class="papertitle">Output Power Maximization in Energy Harvesting Applications</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong> and Shouribrata Chatterjee
                  <br>
                  <em>Undergraduate Thesis (IIT Delhi)</em>, 2014
                  <p>
                    I present exploratory research for increasing the efficiency of an Energy Harvesting Integrated Circuit architecture.
                  </p>
                  <p>
                    <a href="pdf/dtpa.pdf">Pdf</a>
                  </p>
                </td>
              </tr>

              <!-- roshni -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/roshni.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://assistech.iitd.ac.in/doc/Roshni_Pamphlet.pdf">
                  <span class="papertitle">ROSHNI: Indoor Navigation System for Visually Impaired</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>, Devesh Singh, Dhruv Jain and M. Balakrishnan
                  <br>
                  <em>IIT Delhi</em>, 2012
                  <p>
                  </p>
                  <p>
                    <a href="https://assistech.iitd.ac.in/doc/Roshni_Pamphlet.pdf">Roshni IITD</a>
                  </p>
                </td>
              </tr>

              <!-- igwa -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/igwa.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="pdf/igwa.pdf">
                  <span class="papertitle">Elementary Iterative Methods and the Conjugate Gradient Algorithm</span>
                  </a>
                  <br>
                  <strong>Nitin Kamra</strong>
                  <br>
                  <em>High Performance Computing, Indo-German Winter Academy</em>, Dec 2012
                  <p>
                  </p>
                  <p>
                    <a href="pdf/igwa.pdf">Slides</a>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Patents</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- taskopt -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/taskopt.png' onerror="this.style.display='none'" width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://www.freepatentsonline.com/y2023/0342677.html">
                    <span class="papertitle">Task Optimization in an Extended Reality Environment</span>
                  </a>
                  <br>
                  Ruta Parimal Desai and <strong>Nitin Kamra</strong>
                  <br>
                  <em>US Patent Application 20230342677</em>, Filed Apr 21, 2023
                  <br>
                  Reality Labs Research, Meta
                  <p>
                    We present a goal-conditioned agent to enhance a user's ability and efficiency in performing tasks in an extended reality environment. The agent observes egocentric image input from a head-mounted device, generates a symbolic task state, plans a sequence of actions to achieve the desired task goal, and renders visual aid on the display of the head-mounted device to guide the user.
                  </p>
                  <p>
                    <a href="https://www.freepatentsonline.com/y2023/0342677.html">Link</a> |
                    <a href="https://patents.google.com/patent/US20230342677A1/en">Link2</a> |
                    <a href="bib/desai2023ogtm.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

              <!-- correction -->
              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one" style="width:300px;height:auto">
                    <img src='images/correction.png' width=300>
                  </div>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="http://www.freepatentsonline.com/10650811.html"><span class="papertitle">Correction of Speech Recognition on Repetitive Queries</span>
                  </a>
                  <br>
                  Pinar Donmez Ediz, Ranjitha Kulkarni, Shawn Chang and <strong>Nitin Kamra</strong>
                  <br>
                  <em>US patent 10,650,811</em>, Issued May 12, 2023
                  <br>
                  Microsoft AI and Research, Summer 2017
                  <p>
                    We present a system to improve speech recognition by detecting and correcting speech recognition errors during a speech session. The system recognizes repeated speech commands from a user in a session that are similar or identical to each other. To correct these repeated errors, the system creates a customized language model that is then utilized by the language modeler to produce a refined prediction of the meaning of the repeated speech commands.
                  </p>
                  <p>
                    <a href="http://www.freepatentsonline.com/10650811.html">Link</a> |
                    <a href="bib/ediz2020correction.bib">Bibtex</a>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Teaching</h2>
                  <ul>
                    <li>Teaching Assistant for CS-567: Machine Learning, USC (Spring 2020, Fall 2016)</li>
                    <li><a href="posts/rl_tut.pdf">Tutorial</a> for Reinforcement Learning, CS-699: Advanced topics in Deep Learning, USC (Spring 2019)</li>
                    <li>Hosted the <a href="https://sites.google.com/view/agi-rg-usc">Artificial General Intelligence Reading Group</a> at USC (Fall 2018)</li>
                    <li>Teaching Assistant for EEL301: Control Engg - I, IIT Delhi (Spring 2014)</li>
                    <li>Teaching Assistant for EEL201: Digital Electronics, IIT Delhi (Fall 2013)</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Awards</h2>
                  <ul>
                    <li><strong>Deep Learning Best Theory Project Award</strong>, CS-599: Deep
                      Learning, University of Southern California (2017)</li>
                    <li><strong>Viterbi Graduate Ph.D. Fellowship</strong>, University of Southern California (2014-18)</li>
                    <li><strong>Best Mentor Award</strong>, Awarded by <a href="http://smp.iitd.ac.in/">Mentorship Review Committee</a>, Indian Institute of Technology, Delhi (2013)</li>
                    <li><a href="http://www.sofworld.org/imo">SOF 3rd International Mathematics Olympiad</a>, <strong>International Rank 16, School Topper and Gold Medalist</strong> (2010)</li>
                    <li><a href="http://www.sofworld.org/nso">SOF 12th National Science Olympiad</a>, <strong>National Rank 45, School Topper and Gold Medalist</strong> (2010)</li>
                    <li>FIITJEE Talent Reward Exam, <strong>Zonal Topper and Gold Medalist</strong> (2009)</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Adapted from the <a href="https://github.com/jonbarron/jonbarron.github.io"
                      style="font-size:small;">coolest template</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
    </tbody>
  </table>
</body>

</html>